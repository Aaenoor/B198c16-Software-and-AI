{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qw4d1niek38",
        "outputId": "252be9d4-871d-4281-fb6d-1c68ac5fbb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.5135 - loss: 0.8805 - val_accuracy: 0.7143 - val_loss: 0.6388 - learning_rate: 0.0010\n",
            "Epoch 2/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6667 - loss: 0.6625 - val_accuracy: 0.7357 - val_loss: 0.5987 - learning_rate: 0.0010\n",
            "Epoch 3/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7143 - loss: 0.6023 - val_accuracy: 0.7214 - val_loss: 0.5844 - learning_rate: 0.0010\n",
            "Epoch 4/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7486 - loss: 0.5431 - val_accuracy: 0.7357 - val_loss: 0.5586 - learning_rate: 0.0010\n",
            "Epoch 5/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7468 - loss: 0.4934 - val_accuracy: 0.7214 - val_loss: 0.5545 - learning_rate: 0.0010\n",
            "Epoch 6/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 0.6096 - val_accuracy: 0.7286 - val_loss: 0.5344 - learning_rate: 0.0010\n",
            "Epoch 7/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7310 - loss: 0.5213 - val_accuracy: 0.7357 - val_loss: 0.5130 - learning_rate: 0.0010\n",
            "Epoch 8/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.5417 - val_accuracy: 0.7429 - val_loss: 0.5101 - learning_rate: 0.0010\n",
            "Epoch 9/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7365 - loss: 0.4801 - val_accuracy: 0.7571 - val_loss: 0.4900 - learning_rate: 0.0010\n",
            "Epoch 10/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.5102 - val_accuracy: 0.7429 - val_loss: 0.4892 - learning_rate: 0.0010\n",
            "Epoch 11/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.4847 - val_accuracy: 0.7429 - val_loss: 0.4843 - learning_rate: 0.0010\n",
            "Epoch 12/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5679 - val_accuracy: 0.7500 - val_loss: 0.4843 - learning_rate: 0.0010\n",
            "Epoch 13/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.4632 - val_accuracy: 0.7786 - val_loss: 0.4767 - learning_rate: 0.0010\n",
            "Epoch 14/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7826 - loss: 0.4678 - val_accuracy: 0.7857 - val_loss: 0.4702 - learning_rate: 0.0010\n",
            "Epoch 15/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.4634 - val_accuracy: 0.7786 - val_loss: 0.4717 - learning_rate: 0.0010\n",
            "Epoch 16/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.4774 - val_accuracy: 0.7643 - val_loss: 0.4858 - learning_rate: 0.0010\n",
            "Epoch 17/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4272 - val_accuracy: 0.7714 - val_loss: 0.4995 - learning_rate: 0.0010\n",
            "Epoch 18/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.4958 - val_accuracy: 0.7714 - val_loss: 0.4926 - learning_rate: 0.0010\n",
            "Epoch 19/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.4482 - val_accuracy: 0.7643 - val_loss: 0.4867 - learning_rate: 0.0010\n",
            "Epoch 20/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.4386 - val_accuracy: 0.7714 - val_loss: 0.4762 - learning_rate: 5.0000e-04\n",
            "Epoch 21/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.4100 - val_accuracy: 0.7714 - val_loss: 0.4710 - learning_rate: 5.0000e-04\n",
            "Epoch 22/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.4913 - val_accuracy: 0.7643 - val_loss: 0.4694 - learning_rate: 5.0000e-04\n",
            "Epoch 23/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 0.4536 - val_accuracy: 0.7643 - val_loss: 0.4682 - learning_rate: 5.0000e-04\n",
            "Epoch 24/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4946 - val_accuracy: 0.7714 - val_loss: 0.4710 - learning_rate: 5.0000e-04\n",
            "Epoch 25/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4347 - val_accuracy: 0.7714 - val_loss: 0.4747 - learning_rate: 5.0000e-04\n",
            "Epoch 26/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5224 - val_accuracy: 0.7714 - val_loss: 0.4731 - learning_rate: 5.0000e-04\n",
            "Epoch 27/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7978 - loss: 0.4362 - val_accuracy: 0.7714 - val_loss: 0.4700 - learning_rate: 5.0000e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7663 - loss: 0.4730 - val_accuracy: 0.7786 - val_loss: 0.4673 - learning_rate: 5.0000e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.4640 - val_accuracy: 0.7786 - val_loss: 0.4653 - learning_rate: 5.0000e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.4768 - val_accuracy: 0.7786 - val_loss: 0.4605 - learning_rate: 5.0000e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.4669 - val_accuracy: 0.7857 - val_loss: 0.4626 - learning_rate: 5.0000e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.4807 - val_accuracy: 0.7714 - val_loss: 0.4658 - learning_rate: 5.0000e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7793 - loss: 0.4856 - val_accuracy: 0.7714 - val_loss: 0.4736 - learning_rate: 5.0000e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.4039 - val_accuracy: 0.7786 - val_loss: 0.4733 - learning_rate: 5.0000e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.4532 - val_accuracy: 0.7786 - val_loss: 0.4699 - learning_rate: 5.0000e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.4463 - val_accuracy: 0.7786 - val_loss: 0.4703 - learning_rate: 2.5000e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.4738 - val_accuracy: 0.7786 - val_loss: 0.4648 - learning_rate: 2.5000e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4151 - val_accuracy: 0.7786 - val_loss: 0.4643 - learning_rate: 2.5000e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4949 - val_accuracy: 0.7714 - val_loss: 0.4646 - learning_rate: 2.5000e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.4299 - val_accuracy: 0.7714 - val_loss: 0.4649 - learning_rate: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Accuracy: 0.77\n",
            "Precision: 0.75\n",
            "Recall: 0.83\n",
            "F1 Score: 0.79\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/pima-indians-diabetes.data.csv'\n",
        "data = pd.read_csv(file_path, header=None)\n",
        "data.columns = [\n",
        "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "    'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'\n",
        "]\n",
        "\n",
        "# Replace zeros with NaN for specific columns and fill with median\n",
        "columns_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "data[columns_with_zeros] = data[columns_with_zeros].replace(0, np.nan)\n",
        "data.fillna(data.median(), inplace=True)\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(data.iloc[:, :-1])\n",
        "y = data['Outcome']\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build the improved neural network model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping and learning rate reduction\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=150, batch_size=16, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"improved_diabetes_predictor_model.h5\")\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the enhanced chatbot class\n",
        "class MedAIChatbot:\n",
        "    def __init__(self, model_path, scaler):\n",
        "        self.model = load_model(model_path)\n",
        "        self.scaler = scaler\n",
        "        self.features = [\n",
        "            \"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\",\n",
        "            \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"\n",
        "        ]\n",
        "        # Predefined responses for common questions\n",
        "        self.common_questions = {\n",
        "            \"services\": \"MedAI offers early disease detection, a diabetes symptom checker, personalized treatment plans, and expert healthcare consultations.\",\n",
        "            \"diabetes symptom checker\": \"The diabetes symptom checker uses AI to analyze patient data for early detection of diabetes.\",\n",
        "            \"appointment\": \"You can schedule an appointment by providing your preferred date and time. Type 'schedule' followed by your details.\",\n",
        "            \"contact\": \"You can contact MedAI at contact@medai.com or call us at +1-800-555-MEDAI.\",\n",
        "            \"medical advice\": (\n",
        "                \"Here are some general tips:\\n\"\n",
        "                \"1. Maintain a balanced diet rich in fruits, vegetables, and lean proteins.\\n\"\n",
        "                \"2. Exercise regularly—at least 30 minutes of moderate activity per day.\\n\"\n",
        "                \"3. Stay hydrated and drink plenty of water.\\n\"\n",
        "                \"4. Get enough sleep (7-9 hours daily).\\n\"\n",
        "                \"5. Consult a doctor if you experience unusual symptoms or health issues.\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "    def handle_common_question(self, question):\n",
        "        \"\"\"Handle questions based on keywords.\"\"\"\n",
        "        keyword_responses = {\n",
        "            (\"service\", \"services\", \"medai\"): self.common_questions[\"services\"],\n",
        "            (\"symptom\", \"checker\", \"diabetes\"): self.common_questions[\"diabetes symptom checker\"],\n",
        "            (\"schedule\", \"appointment\", \"book appointment\"): self.common_questions[\"appointment\"],\n",
        "            (\"contact\", \"number\", \"phone\", \"contact details\"): self.common_questions[\"contact\"],\n",
        "            (\"tip\", \"health tip\", \"advice\", \"medical advice\"): self.common_questions[\"medical advice\"],\n",
        "            (\"bye\", \"exit\"): \"Goodbye!\"\n",
        "        }\n",
        "\n",
        "        # Match user input to keywords\n",
        "        for keywords, response in keyword_responses.items():\n",
        "            if any(keyword in question for keyword in keywords):\n",
        "                return response\n",
        "\n",
        "        # Fallback for unmatched questions\n",
        "        return \"I'm sorry, I didn't understand your question. Can you please rephrase?\"\n",
        "\n",
        "    def handle_appointment(self, details):\n",
        "        \"\"\"Handle appointment scheduling.\"\"\"\n",
        "        return f\"Appointment scheduled successfully with the following details: {details}\"\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        if isinstance(user_input, dict):\n",
        "            # Predictive response for diabetes check\n",
        "            try:\n",
        "                # Check for missing features\n",
        "                missing_features = [feature for feature in self.features if feature not in user_input or user_input[feature] is None]\n",
        "                if missing_features:\n",
        "                    return f\"Missing features: {', '.join(missing_features)}. Please provide all required inputs.\"\n",
        "\n",
        "                # Extract and validate feature values\n",
        "                values = [float(user_input[feature]) for feature in self.features]\n",
        "\n",
        "                # Create a DataFrame with feature names\n",
        "                input_data = pd.DataFrame([values], columns=self.features)\n",
        "                values = []\n",
        "                for feature in self.features:\n",
        "                    value = user_input.get(feature)\n",
        "                    values.append(float(value))\n",
        "\n",
        "                input_data_scaled = self.scaler.transform([values])\n",
        "\n",
        "                # Predict using the model\n",
        "                prediction = self.model.predict(input_data_scaled)[0][0]\n",
        "                diagnosis = \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "                return f\"Prediction: {diagnosis}. Probability: {prediction:.2f}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                # Log exception (optional) and return a user-friendly message\n",
        "                print(f\"Error: {str(e)}\")  # Log the error for debugging\n",
        "                return \"An error occurred while processing your data. Please try again.\"\n",
        "\n",
        "        elif isinstance(user_input, str):\n",
        "            # Lowercase for consistency\n",
        "            question = user_input.lower().strip()\n",
        "            if question.startswith(\"schedule\"):\n",
        "                # Extract appointment details by removing the keyword 'schedule'\n",
        "                details = question[len(\"schedule\"):].strip()  # Extract the rest of the string after 'schedule'\n",
        "                # Check if the details are provided or empty\n",
        "                if not details:\n",
        "                    return \"Please provide appointment details, such as the date and time (e.g., 'schedule 15th March at 3 PM').\"\n",
        "                # Optionally validate the details for basic formatting\n",
        "                return self.handle_appointment(details)\n",
        "\n",
        "            # Handle dynamic keyword-based questions\n",
        "            return self.handle_common_question(question)\n",
        "\n",
        "        else:\n",
        "            return \"Invalid input. Please provide a valid question or diabetes data.\"\n",
        "\n",
        "\n",
        "# Instantiate the chatbot\n",
        "#scaler = joblib.load(\"scaler.pkl\")  # Ensure your scaler is loaded here (e.g., from joblib or pickle)\n",
        "chatbot = MedAIChatbot(\"improved_diabetes_predictor_model.h5\", scaler)\n",
        "\n",
        "# Interact with the chatbot\n",
        "print(\"MedAI Chatbot is ready! Type 'exit' or 'bye' to quit.\")\n",
        "while True:\n",
        "    print(\"\\nAsk a healthcare question or provide diabetes data as a JSON-like dictionary.\")\n",
        "    print(\"Example: {'Glucose': 120, 'BMI': 30.5, ...} or 'What are MedAI's services?'\")\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"exit\", \"bye\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    try:\n",
        "        # Determine if input is JSON-like or a string\n",
        "        if user_input.startswith(\"{\") and user_input.endswith(\"}\"):\n",
        "            user_data = eval(user_input)  # Convert string input to a Python dictionary\n",
        "        else:\n",
        "            user_data = user_input  # Treat as a general question\n",
        "        response = chatbot.get_response(user_data)\n",
        "        print(\"Bot:\", response)\n",
        "    except Exception as e:\n",
        "        print(\"Bot: Invalid input. Please provide data in the correct format.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aZlmbV0ZEWt",
        "outputId": "98378a18-411b-41e2-f2d3-a522214ecac2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedAI Chatbot is ready! Type 'exit' or 'bye' to quit.\n",
            "\n",
            "Ask a healthcare question or provide diabetes data as a JSON-like dictionary.\n",
            "Example: {'Glucose': 120, 'BMI': 30.5, ...} or 'What are MedAI's services?'\n",
            "User: bye\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}